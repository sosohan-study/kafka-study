# 컨슈머의 기본 동작과 예제 
 
컨슈머는 토픽에 저장되어 있는 메시지를 가져오는 역할을 담당한다.       
컨슈머가 단순하게 카프카로부터 메시지만 가져오는 것 같지만,         
내부적으로는 컨슈머 그룹, 리밸런싱 등 여러 동작을 수행한다.      
      
이러한 컨슈머의 기본 동작과 옵션을 잘 이해한다면 내가 원하는 형태로 컨슈머를 구성, 운영할 수 있다.        
프로듀서로 아무리 빠르게 메시지를 전송하더라도 컨슈머가 카프카로부터 빠르게 메시지를 읽어오지 못한다면 결국 지연이 발생한다.       

# 컨슈머의 기본 동작   
컨슈머 그룹은 하나 이상의 컨슈머들이 모여있는 그룹을 의미하고 컨슈머는 반드시 컨슈머 그룹에 속해야한다.         
**컨슈머 그룹은 각 파티션의 리더에게 카프카 토픽에 저장된 메시지를 가져오기 위한 요청을 보낸다.**       
     
이때, 파티션 수와 컨슈머 수는 1대1로 매핑되는 것이 가장 이상적이다.    
컨슈머 수가 파티션 수보다 많다고 해서 토픽의 메시지를 더 빠르게 가져오거나 처리량이 높아지는 것은 아니다.        
오히려 많은 수의 컨슈머들이 그냥 대기 상태로 존재하게 되는 문제가 발생한다.    
      
액티브/스탠바이 개념으로 추가 컨슈머가 더 있으면 좋을 것이라고 생각할 수도 있지만,    
**컨슈머 그룹내에서 리밸런싱 동작을 통해 장애가 발생한 컨슈머의 역할을 동일한 그룹에 있는 다른 컨슈머가 그 역할을 대신 수행하므로**         
굳이 장애 대비를 위한 추가 컨슈머 리소스를 할당하지 않아도 된다.          
(즉, 장애 발생시 다른 컨슈머가 여러 파티션에 대해서 작업을 처리해줄 수 있다.)   

# 컨슈머의 주요 옵션  

카프카에는 메시지가 잘 저장되어 있어도   
관리자가 컨슈머를 어떻게 처리하고 다루느냐에 따라    
컨슈머 동작에서 메시지의 중복, 유실등 여러가지 상황이 발생할 수 있다.    

컨슈머를 사용하는 목적이 최대한 안정적이며 지연이 없도록 카프카로부터 메시지를 가져오는 것인데,   
이를 위한 옵션을 잘이해하고 사용해야만 자신이 원하는 형태로 컨슈머가 동작할 것이다.  
컨슈머는 옵션에 따라 오토 커밋, 배치 등의 설정을 할 수 있다.  

|컨슈머 옵션|설명|
|--------|---|
|bootstrap.servers|프로듀서와 동일하게 브로커의 정보를 입력한다|   
|fetch.min.bytes|한번에 가져올 수 있는 최소 데이터크기다.<br>만약 지정한 크기보다 작은 경우, 요청에 응답하지 않고 데이터가 누적될때까지 기다린다.|   
|group.id|컨슈머가 속한 커슈머 그룹을 식별하는 식별자다.<br>동일한 그룹내의 컨슈머 정보는 모두 공유된다.|   
|heartbeat.interval.ms|하트비트가 있다는 것은 컨슈머의 상태가 active임을 의미한다.<br>session.timeout.ms와 밀접한 관계가 있으며,<br>session.timeout.ms보다 낮은값으로 설정해야한다.<br>일반적으로 session.timeout.ms의 1/3 크기로 해야한다.|
|max.partition.fetch.bytes|파티션당 가져올 수 있는 최대 크기를 의미한다.|   
|session.timeout.ms|이 시간을 이용해, 컨슈머가 종료된 것인지 판단한다.<br>컨슈머는 주기적으로 하트비트를 보내야하고,<br>만약 이 시간전까지 하트비트를 보내지 않았다면 해당 컨슈머는 종료된 것으로 간주하고<br>컨슈머 그룹에서 제외하고 리밸런싱을 시작한다|
|enable.auto.commit|백그라운드로 주기적으로 오프셋을 커밋한다.|
|auto.offset.reset|카프카에서 초기 오프셋이 없거나<br>현재 오프셋이 더이상 조재하지 않는 경우에 다음 옵션으로 reset한다.<br>* earliest: 가장 초기의 오프셋값으로 설정한다.<br>* latest: 가장 마지막의 오프셋값으로 설정한다.<br>* none: 이전 오프셋값을 찾지 못하면 에러를 나타낸다.|
|fetch.max.bytes|한 번의 가져오기 요청으로 가져올 수 있는 최대 크기다.|
|group.instance.id|컨슈머의 고유한 식별자이다.<br>만약 설정한다면 static 멤버로 간주되어, 불필요한 리밸린성을 하지 않는다.|   
|isolation.level|트랜잭션 컨슈머에서 사용되는 옵션으로,<br>read_uncommitted는 기본값으로 모든 메시지를 읽고,<br>read_committed는 트랜잭션이 완료된 메시지만 읽는다.|  
|max.poll.records|한번의 `poll()` 요청으롷 가져오는 최대 메시지 수이다.|   
|partitions.assignment.strategy|파티션 할당 전략이며, 기본값은 range이다.|    
|fetch.max.wait.ms|fetch.min.bytes에 의해 설정된 데이터보다 적은 경우 요청에 대한 응답을 기다리는 최대 시간이다.|    

# 컨슈머 예제 

컨슈머에서 메시지를 가져오는 방식은 크게 3가지가 있다.   

* 오토 커밋 
* 동기 가져오기 
* 비동기 가죠오기 
 
## 오토 커밋 

```kt
class ConsumerAuto

fun main(args: Array<String>) {
    val props = Properties() //Properties 오브젝트를 시작합니다.
    props["bootstrap.servers"] = "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092" //브로커 리스트를 정의합니다.
    props["group.id"] = "peter-consumer01" //컨슈머 그룹 아이디 정의합니다.
    props["enable.auto.commit"] = "true" //자동 커밋을 사용합니다.
    props["auto.offset.reset"] = "latest" //컨슈머 오프셋을 찾지 못하는 경우 latest로 초기화 합니다. 가장 최근부터 메시지를 가져오게 됩니다.
    props["key.deserializer"] = "org.apache.kafka.common.serialization.StringDeserializer" //문자열을 사용했으므로 StringDeserializer 지정합니다.
    props["value.deserializer"] = "org.apache.kafka.common.serialization.StringDeserializer"
    val consumer: KafkaConsumer<String, String> = KafkaConsumer(props) //Properties 오브젝트를 전달하여 새 컨슈머를 생성합니다.
    consumer.subscribe(listOf("peter-basic01")) //구독할 토픽을 지정합니다.
    try {
        while (true) { //무한 루프 시작입니다. 메시지를 가져오기 위해 카프카에 지속적으로 poll()을 하게 됩니다.
            val records = consumer.poll(Duration.ofMillis(1000)) //컨슈머는 폴링하는 것을 계속 유지하며, 타임 아웃 주기를 설정합니다.해당 시간만큼 블럭합니다.
            for (record in records) { //poll()은 레코드 전체를 리턴하고, 하나의 메시지만 가져오는 것이 아니므로, 반복문 처리합니다.
                System.out.printf(
                    "Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
                    record.topic(), record.partition(), record.offset(), record.key(), record.value()
                )
            }
        }
    } catch (e: Exception) {
        e.printStackTrace()
    } finally {
        consumer.close() //컨슈머를 종료합니다.
    }
}
```
  
**컨슈머 생성에 필요한 properties 데이터**    
* 브로커 리스트를 정의한다.     
* 컨슈머 그룹 아이디를 정의한다.    
* **자동 커밋 사용을 적용한다.**      
* 오프셋을 찾지 못할 경우 latest로 초기화 -> 최근 메시지부터 받아온다.   
* 문자열 직렬화 설정 정보를 입력한다.   
  
프로퍼티스 설정을 통해서 컨슈머를 생성하고 구독할 토픽을 정한다.       
   
**무한루프를 통해서 지속적으로 메시지를 가져오고 이 과정에서 `poll()`기법을 사용한다.**       
컨슈머는 폴링을 유지하면서 타임아웃 주기를 설정하고 해당 시간만큼 블락킹한다.        
폴링으로 받아온 메시지'들'을 가져온다.    
  
오토커밋은 컨슈머 애플리케이션들의 기본값으로 가장 많이 사용되고 있다.       
오토커밋은 오프셋을 주기적으로 커밋(폴링)하므로 관리자가 오프셋을 따로 관리하지 않아도 되는 장점이 있다.       
하지만, 컨슈머 종료 등이 빈번히 일어나면 일부 메시지를 못 가져오거나 중복으로 가져오는 경우가 있다.     
(폴링인 직접 데이터를 조회하는건데 이 과정에서 데이터를 못가져오거나 중복이 될 수 있다는 것이다.)      
  
카프카는 굉장히 안정적으로 잘 동작하고, 컨슈머 역시 한번 구동하고 나면 자주 변경되거나 종료되지는 않기에 오토커밋을 주로 사용한다.      
   
## 동기 가져오기 

```kt
class ConsumerSync

fun main(args: Array<String>) {
    val props = Properties() //Properties 오브젝트를 시작합니다.
    props["bootstrap.servers"] =
        "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092" //브로커 리스트를 정의합니다.
    props["group.id"] = "peter-consumer01" //컨슈머 그룹 아이디 정의합니다.
    props["enable.auto.commit"] = "false" //자동 커밋을 사용하지 않습니다.
    props["auto.offset.reset"] = "latest" //컨슈머 오프셋을 찾지 못하는 경우 latest로 초기화 합니다. 가장 최근부터 메시지를 가져오게 됩니다.
    props["key.deserializer"] =
        "org.apache.kafka.common.serialization.StringDeserializer" //문자열을 사용했으므로 StringDeserializer 지정합니다.
    props["value.deserializer"] = "org.apache.kafka.common.serialization.StringDeserializer"
    val consumer: KafkaConsumer<String, String> = KafkaConsumer(props) //Properties 오브젝트를 전달하여 새 컨슈머를 생성합니다.
    consumer.subscribe(listOf("peter-basic01")) //구독할 토픽을 지정합니다.
    try {
        while (true) { //무한 루프 시작입니다. 메시지를 가져오기 위해 카프카에 지속적으로 poll()을 하게 됩니다.
            val records = consumer.poll(Duration.ofMillis(1000)) //컨슈머는 폴링하는 것을 계속 유지하며, 타임 아웃 주기를 설정합니다.해당 시간만큼 블럭합니다.
            for (record in records) { //poll()은 레코드 전체를 리턴하고, 하나의 메시지만 가져오는 것이 아니므로, 반복문 처리합니다.
                System.out.printf(
                    "Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
                    record.topic(), record.partition(), record.offset(), record.key(), record.value()
                )
            }
            // 여기가 중요 
            consumer.commitSync() //현재 배치를 통해 읽은 모든 메시지들을 처리한 후, 추가 메시지를 폴링하기 전 현재의 오프셋을 커밋합니다.
        }
    } catch (e: Exception) {
        e.printStackTrace()
    } finally {
        consumer.close() //컨슈머를 종료합니다.
    }
}
```

**컨슈머 생성에 필요한 properties 데이터**    
* 브로커 리스트를 정의한다.     
* 컨슈머 그룹 아이디를 정의한다.    
* **자동 커밋 사용을 적용하지 않는다.**      
* 오프셋을 찾지 못할 경우 latest로 초기화 -> 최근 메시지부터 받아온다.   
* 문자열 직렬화 설정 정보를 입력한다.   
  
프로퍼티스 설정을 통해서 컨슈머를 생성하고 구독할 토픽을 정한다.       
   
**무한루프를 통해서 지속적으로 메시지를 가져오고 이 과정에서 `poll()`기법을 사용한다.**       
컨슈머는 폴링을 유지하면서 타임아웃 주기를 설정하고 해당 시간만큼 블락킹한다.        
폴링으로 받아온 메시지'들'을 가져온다.    

오토 커밋과 달리 poll()을 이용해 메시지를 가져온 후 **처리까지 완료하고 현재의 오프셋을 커밋한다.**       
즉, 오토 커밋과 달리 `consumer.commitSync()`와 같이 명시적으로 커밋을 날린다.   
 
동기 방식으로 가져오는 경우 속도는 느리지만, 메시지 손실은 거의 발생하지 않는다.     
여기서 메시지 손실이란, 실제로 토픽에는 메시지가 존재하지만 잘못된 오프셋 커밋으로 인한 위치 변경으로     
컨슈머가 메시지를 가져오지 못하는 경우를 말한다.     

메시지가 손실되면 안되는 중요한 처리들은 동기 방식으로 진행하는 것을 권장한다.     
하지만, 이 방법도 메시지 중복 이슈는 피할 수 없다.    

## 비동기 가져오기 

```kt
class ConsumerAsync

fun main(args: Array<String>) {
    val props = Properties() //Properties 오브젝트를 시작합니다.
    props["bootstrap.servers"] = "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092" //브로커 리스트를 정의합니다.
    props["group.id"] = "peter-consumer01" //컨슈머 그룹 아이디 정의합니다.
    props["enable.auto.commit"] = "false" //자동 커밋을 사용하지 않습니다.
    props["auto.offset.reset"] = "latest" //컨슈머 오프셋을 찾지 못하는 경우 latest로 초기화 합니다. 가장 최근부터 메시지를 가져오게 됩니다.
    props["key.deserializer"] = "org.apache.kafka.common.serialization.StringDeserializer" //문자열을 사용했으므로 StringDeserializer 지정합니다.
    props["value.deserializer"] = "org.apache.kafka.common.serialization.StringDeserializer"
    val consumer: KafkaConsumer<String, String> = KafkaConsumer(props) //Properties 오브젝트를 전달하여 새 컨슈머를 생성합니다.
    consumer.subscribe(listOf("peter-basic01")) //구독할 토픽을 지정합니다.
    try {
        while (true) { //무한 루프 시작입니다. 메시지를 가져오기 위해 카프카에 지속적으로 poll()을 하게 됩니다.
            val records = consumer.poll(Duration.ofMillis(1000)) //컨슈머는 폴링하는 것을 계속 유지하며, 타임 아웃 주기를 설정합니다.해당 시간만큼 블럭합니다.
            for (record in records) { //poll()은 레코드 전체를 리턴하고, 하나의 메시지만 가져오는 것이 아니므로, 반복문 처리합니다.
                System.out.printf(
                    "Topic: %s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
                    record.topic(), record.partition(), record.offset(), record.key(), record.value()
                )
            }
            consumer.commitAsync() //현재 배치를 통해 읽은 모든 메시지들을 처리한 후, 추가 메시지를 폴링하기 전 현재의 오프셋을 비동기 커밋합니다.
        }
    } catch (e: Exception) {
        e.printStackTrace()
    } finally {
        consumer.close() //컨슈머를 종료합니다.
    }
}
```

**컨슈머 생성에 필요한 properties 데이터**    
* 브로커 리스트를 정의한다.     
* 컨슈머 그룹 아이디를 정의한다.    
* **자동 커밋 사용을 적용하지 않는다.**      
* 오프셋을 찾지 못할 경우 latest로 초기화 -> 최근 메시지부터 받아온다.   
* 문자열 직렬화 설정 정보를 입력한다.   

프로퍼티스 설정을 통해서 컨슈머를 생성하고 구독할 토픽을 정한다.       
   
**무한루프를 통해서 지속적으로 메시지를 가져오고 이 과정에서 `poll()`기법을 사용한다.**       
컨슈머는 폴링을 유지하면서 타임아웃 주기를 설정하고 해당 시간만큼 블락킹한다.        
폴링으로 받아온 메시지'들'을 가져온다.  

오프셋 1번부터 10번까지 순서대로 커밋을 했다고 가정하면 아래와 같다.   

1. 1번 오프셋의 메시지를 읽은 뒤 1번 오프셋을 비동기 커밋한다.(현재 마지막 오프셋 1)  
2. 2번 오프셋의 메시지를 읽은 뒤 2번 오프셋을 비동기 커밋하지만 실패(현재 마지막 오프셋 1)
3. 3번 오프셋의 메시지를 읽은 뒤 3번 오프셋을 비동기 커밋하지만 실패(현재 마지막 오프셋 1)
4. 4번 오프셋의 메시지를 읽은 뒤 4번 오프셋을 비동기 커밋하지만 실패(현재 마지막 오프셋 1)
5. 5번 오프셋의 메시지를 읽은 뒤 5번 오프셋을 비동기 커밋(현재 마지막 오프셋 5)
   
`consumer.commitAsync()`는 오프셋 커밋을 실패하더라도 재시도를 하지 않는다.         
만약, 2번 오프셋이 재시도로 성공을 하면 마지막 오프셋이 2가 되고 3번부터 다시 작업하므로 중복이 이루어진다.       
이러한 이유로 비동기의 경우에는 커밋을 재시도 하지는 않는다.    

비동기 방식을 좀더 보완하기 위해 콜백을 사용하는 경우도 있으니 나중에 참고하자   

# 컨슈머 그룹의 이해 
  
컨슈머는 컨슈머 그룹안에 속한 것이 일반적인 구조다.      
그리고 하나의 컨슈머 그룹안에 여러 개의 컨슈머가 구성될 수 있다.     

![Kafka-Consumer-Group_2](https://user-images.githubusercontent.com/50267433/148414901-b30c3600-e529-4287-898b-47596e73c7a4.png)

컨슈머들은 하나의 컨슈머 그룹안에 속해 있으며,    
그룹내의 컨슈머들은 서로의 정보를 공유한다.     
즉, 하나의 컨슈머가 문제가 생기더라도 다른 컨슈머가 해당 컨슈머의 파티션의 데이터를 컨슘해준다.   
