 
# 프로듀서 기본 동작과 예제 

프로듀서는 카프카의 토픽으로 메시지를 전송하는 역할을 담당한다.       
프로듀서는 여러 옵션을 제공하므로,    
원하는 형태에 따라 옵션을 변경하면서 다양한 방법으로 카프카로 메시지를 전송할 수 있다.      

# 프로듀서 디자인 

![img](https://user-images.githubusercontent.com/50267433/148359791-ce439f0c-7472-45c2-a099-b2e8d16c1af8.png)

**ProducerRecor**
* 카프카로 데이터를 전송하기 위한 실제 데이터이며 토픽, 파티션 키, 벨류로 구성되어 있다.           
* 필숫값    
    * 토픽    
    * 벨류(메시지 내용)     
    * 프로듀서가 카프카로 레코드를 전송할 때, 카프카의 특정 토픽으로 메시지를 전송함으로                 
* 선택사항  
    * 파티션 : 특정 파티션을 지정하기 위한 파티션      
    * 키 : 특정 파티션에 레코드들을 정렬하기 위한 키        

각 레코드들은 프로듀서의 send() 메서드를 통해 시리얼라이저, 파티셔너를 거치게 된다.         
만약, 프로듀서 레코드의 선택사항인 파티션을 지정했다면,           
파티셔너는 아무 동작도 하지 않고 지정된 파티션으로 레코드를 전달한다.  

파티션을 지정하지 않은 경우에는 키를 가지고 파티션을 선택해 레코드를 전달하는데, 기본적으로 라운드 로빈 방식으로 동작한다.    
  
이렇게 프로듀서 내부에서는 send() 동작 이후 레코드들을 파티션별로 잠시 모아둔다.       
레코드들을 모아두는 이유는 프로듀서가 카프카로 전송하기 전, 배치 전송을 하기 위함이다.    
   
전송이 실패하면 재시도 동작이 이뤄지고 지정된 횟수만큼의 재시도가 실패하면 최종 실패를 전달하며,     
전송이 성공하면 메타 데이터를 리턴하게 된다.       

# 프로듀서 주요 옵션 

|프로듀서 옵션|설명|
|----------|---|
|bootstrap.servers|카프카 클러스터는 클러스터 마스터라는 개념이 없으므로,<br>클러스터 내 모든 서버가 클라이언트의 요청을 받을 수 있다.<br>클라이언트가 카프카 클러스터에 처음 연결하기 위한 호스트와 포트 정보를 나타낸다.<br>|
|client.dns.lookup|하나의 호스트에 여러 IP를 매핑해 사용하는 일부 환경에서<br>클라이언트가 하나의 IP와 연결하지 못할 경우에 다른 IP로 시도하는 설정이다.<br>use_all_dns_ips가 기본값으로,<br>DNS에 할당된 호스트의 모든 IP쿼리하고 저장한다.<br>첫 번째 IP접근이 실패하면, 종료하지 않고 다음 IP로 접근을 시도한다.<br>resolve_canonical_bootstrap_servers_only 옵션은<br>커버로스 환경에서 FQDN을 얻기 위한 용도로 사용된다.|
|acks|프로듀서가 카프카 토픽의 리더 측에 메시지를 전송한 후 요청을 완료하기를 정하는 옵션이다.<br>0/1/all(-1)로 표현하며<br>0은 빠른 전송을 의미하지만, 일부 메시지 손실 가능성이 있다.<br>1은 리더가 메시지를 받았는지 확인하지만, 모든 팔로워를 전부 확인하지는 않는다.<br>대부분은 기본값으로 1을 사용한다<br>all은 팔로워가 메시지를 받았는지 여부를 확인한다<br>다소 느릴수는 있지만, 하나의 팔로워가 있는 한 메시지는 손실되지 않는다.| 
|buffer.memory|프로듀서가 카프카 서버로 데이터를 보내기 위해 잠시 대기(배치 전송이나 딜레이등)할 수 있는 전체 메모리 바이트|
|compression.type|프로듀서가 메시지 전송시 선택할 수 있는 압축타입이다.<br>none, gzip, snappy, lz4, zstd 중 원하는 타입을 선택할 수 있다.|
|enable.idempotence|설정을 true로 하는 경우 중복 없는 전송이 가능하며,<br>이와 동시에 max.in.flight.request.per.connection은 5이하, retries는 0이상, ack는 all로 설정해야한다.|
|max.in.flight.request.per.connection|하나의 커넥션에서 프로듀서가 최대한 ACK 없이 전송할 수 있는 요청 수다.<br>메시지의 순서가 중요하다면 1로 설정할 것을 권장하지만, 성능은 다소 떨어진다.|
|retries|일시적인 오류로 인해 전송에 실패한 데이터를 다시 보내는 횟수다.|   
|batch.size|프로듀서는 동일한 파티션으로 보내는 여러 데이터를 함께 배치로 보내려고 시도한다.<br>적절한 배치 크기 설정은 성능에 도움을 준다.|    
|linger.ms|배치 형태의 메시지를 보내기전에 추가적인 메시지를 위해 기다리는 시간을 조정하고,<br>배치 크기에 도달하지 못한 상황에서 linger.ms 제한시간에 도달했을 때 메시지를 전송한다.|   
|transactional.id|'정확히 한번 전송'을 위해 사용되는 옵션이며, 동일한 TransactionalId에 한해 정확히 한 번을 보장한다.<br>옵션을 사용하기 전 enable.idempotence를 true를 설정해야한다.|  

# 실습에 앞서 토픽 생성하기

```console
[ec2-user@ip-172-31-46-193 ~]$ 
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 --create --topic peter-basic01 --partitions 1 --replication-factor 3
```
```console
Created topic peter-basic01.
```

# 프로듀서 실습 

프로듀서의 전송방법은 크게 3가지 방식으로 나눌 수 있다.   

* 메시지를 보내고 확인하지 않기
* 동기 전송
* 비동기 전송

## 메시지를 보내고 확인하지 않기 예제 
```kt
class KafkaKotlinApplication

fun main(args: Array<String>) {
    val props = Properties() //Properties 오브젝트를 시작합니다.

    props["bootstrap.servers"] = "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092" //브로커 리스트를 정의합니다.
    props["key.serializer"] = "org.apache.kafka.common.serialization.StringSerializer" // 메시지 키와 벨류에 문자열을 지정하므로 내장된 StringSerializer를 지정합니다.
    props["value.serializer"] = "org.apache.kafka.common.serialization.StringSerializer"

    val producer: Producer<String, String> = KafkaProducer(props) //Properties 오브젝트를 전달해 새 프로듀서를 생성합니다.
    try {
        for (i in 0..2) {
            val record = ProducerRecord<String, String>(
                "peter-basic01",
                "Apache Kafka is a distributed streaming platform - $i"
            ) //ProducerRecord 오브젝트를 생성합니다.
            producer.send(record) //send()메소드를 사용하여 메시지를 전송 후 Java Future Ojbect로 RecordMetadata를 리턴 받지만, 리턴값을 무시하므로 메시지가 성공적으로 전송되었는지 알 수 없습니다.
        }
    } catch (e: Exception) {
        e.printStackTrace() //카프카 브로커에게 메시지를 전송한 후의 에러는 무시하지만, 전송 전 에러가 발생하면 예외를 처리할 수 있습니다.
    } finally {
        producer.close() // 프로듀서 종료
    }
}
```

**프로듀서**
* 메시지가 전송될 브로커 리스트를 정의한다.(서버의 도메인)    
* key와 value 값에 대한 Serializer를 설정하는데 둘다 문자열로 보낼 것이므로 StringSerializer를 사용한다.   
* 위에서 정의된 2가지 요소를 포함한 프로퍼티스를 기반으로 프로듀서 객체를 생성한다.   

**레코드**
* peter-basic01 토픽에 `Apache Kafka is a distributed streaming platform 반복` 메시지를 보낸다.     
   
이후, 프로듀서는 레코드를 `send()`한다.            
Futuer 객체로 RecordMetaData를 리턴받아야되지만 명시하지 않아서 성공적으로 전송되었는지는 모른다.          
카프카 브로커에게 메시지를 전송한 후의 에러는 무시하지만, 전송 전에 에러가 발생하면 에러를 처리할 수 있다.  

## 동기방식 예제 

```kt
class ProducerSync

fun main(args: Array<String>) {
    val props = Properties() //Properties 오브젝트를 시작합니다.
    
    props["bootstrap.servers"] = "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092" //브로커 리스트를 정의합니다.
    props["key.serializer"] = "org.apache.kafka.common.serialization.StringSerializer" //메시지 키와 벨류에 문자열을 지정하므로 내장된 StringSerializer를 지정합니다.
    props["value.serializer"] = "org.apache.kafka.common.serialization.StringSerializer"
    
    val producer: Producer<String, String> = KafkaProducer(props) //Properties 오브젝트를 전달해 새 프로듀서를 생성합니다.
    try {
        for (i in 0..2) {
            val record = ProducerRecord<String, String>(
                "peter-basic01",
                "Apache Kafka is a distributed streaming platform - $i"
            ) //ProducerRecord 오브젝트를 생성합니다.

            //get() 메소드를 이용해 카프카의 응답을 기다립니다. 메시지가 성공적으로 전송되지 않으면 예외가 발생하고, 에러가 없다면 RecordMetadata를 얻게 됩니다.
            val metadata: RecordMetadata = producer.send(record).get() 
            System.out.printf(
                "Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n",
                metadata.topic(),
                metadata.partition(),
                metadata.offset(),
                record.key(),
                record.value()
            )
        }
    } catch (e: Exception) {
        e.printStackTrace() //카프카로 메시지를 보내기 전과 보내는 동안 에러가 발생하면 예외가 발생합니다.
    } finally {
        producer.close() // 프로듀서 종료
    }
}
```

**프로듀서**
* 메시지가 전송될 브로커 리스트를 정의한다.(서버의 도메인)    
* key와 value 값에 대한 Serializer를 설정하는데 둘다 문자열로 보낼 것이므로 StringSerializer를 사용한다.   
* 위에서 정의된 2가지 요소를 포함한 프로퍼티스를 기반으로 프로듀서 객체를 생성한다.   

**레코드**
* peter-basic01 토픽에 `Apache Kafka is a distributed streaming platform 반복` 메시지를 보낸다.     
       
이후, 프로듀서는 레코드를 `send()`한다.                
Futuer 객체로 RecordMetaData를 리턴받고 `get()`을 사용하기에 응답이 올때까지 대기한다는 특성을 가진다.       
일단 ProducerRecord 전송이 성공하고 나면 RecordMetaData를 읽어들여 파티션과 오프셋 정보를 확인할 수 있다.       
이 방법으로 메시지 전달의 성공 여부를 파악할 수 있다.(동기 전송 방식은 신뢰성 있는 메시지 과정의 핵심)   

## 콜백 예제 
  
**PeterProducerCallback**   
```kt
class PeterProducerCallback(private val record: ProducerRecord<String, String>) : Callback {
    //콜백을 사용하기 위해 org.apache.kafka.clients.producer.Callback를 구현하는 클래스가 필요합니다.
    override fun onCompletion(metadata: RecordMetadata, e: Exception?) {
        e?.printStackTrace() //카프카가 오류를 리턴하면 onCompletion()은 예외를 갖게 되며, 실제 운영환경에서는 추가적인 예외처리가 필요합니다.
            ?: System.out.printf(
                "Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n",
                metadata.topic(),
                metadata.partition(),
                metadata.offset(),
                record.key(),
                record.value()
            )
    }
}
```
* 프로듀서에서의 콜백 작업은 `org.apache.kafka.clients.producer.Callback`구현체가 필요하다.    
* 카프카가 오류를 리턴한면 `onCompletion`은 Exception 객체를 가지게된다.     

**ProducerAsync**
```kt
class ProducerAsync

fun main(args: Array<String>) {
    val props = Properties() //Properties 오브젝트를 시작합니다.
    props["bootstrap.servers"] = "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092" //브로커 리스트를 정의합니다.
    props["key.serializer"] = "org.apache.kafka.common.serialization.StringSerializer" //메시지 키와 벨류에 문자열을 지정하므로 내장된 StringSerializer를 지정합니다.
    props["value.serializer"] = "org.apache.kafka.common.serialization.StringSerializer"
    
    val producer: Producer<String, String> = KafkaProducer(props) //Properties 오브젝트를 전달해 새 프로듀서를 생성합니다.
    try {
        for (i in 0..2) {
            val record = ProducerRecord<String, String>(
                "peter-basic01",
                "Apache Kafka is a distributed streaming platform - $i"
            ) //ProducerRecord 오브젝트를 생성합니다.
            producer.send(record, PeterProducerCallback(record)) //프로듀서에서 레코드를 보낼 때 콜백 오브젝트를 같이 보냅니다.
        }
    } catch (e: Exception) {
        e.printStackTrace()
    } finally {
        producer.close() // 프로듀서 종료
    }
}
```
**프로듀서**
* 메시지가 전송될 브로커 리스트를 정의한다.(서버의 도메인)    
* key와 value 값에 대한 Serializer를 설정하는데 둘다 문자열로 보낼 것이므로 StringSerializer를 사용한다.   
* 위에서 정의된 2가지 요소를 포함한 프로퍼티스를 기반으로 프로듀서 객체를 생성한다.   

**레코드**
* peter-basic01 토픽에 `Apache Kafka is a distributed streaming platform 반복` 메시지를 보낸다.     
        
이후, 프로듀서는 레코드를 `send()`한다.            
이 과정에서 콜백 메서드를 전달하면, `send()`가 성공하면 콜백 메서드를 실행한다.        

동기 방식의 경우 프로듀서가 보낸 모든 문자에 대해 응답을 기다리게 되면서 많은 시간을 소비하게한다.     
하지만 비동기 방식으로 전송하면 빠른 전송이 가능하고,     
메시지 전송이 실패한 경우라도 예외를 처리할 수 있어서 이후 에러 로그등을 기록할 수 있다.   

